import os
import gymnasium as gym
from gymnasium.wrappers import RecordVideo
from stable_baselines3 import PPO
from export_onnx import export_policy_to_onnx

# ğŸ¯ Chemins
OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ğŸ¦¾ Charge ton humanoÃ¯de dans Mujoco
# Remplace 'Humanoid-v4' par ton env spÃ©cifique le cas Ã©chÃ©ant
env_id = "Humanoid-v4"

env = gym.make(env_id, render_mode="rgb_array")
#env = gym.make(env_id)

# ğŸ¥ Enregistre une vidÃ©o pendant le training

env = RecordVideo(
    env,
    video_folder=os.path.join(OUTPUT_DIR, "videos"),
    #episode_trigger=lambda ep: True  # Capture au 1er Ã©pisode
    episode_trigger=lambda ep: ep % 3000 == 0  # Une vidÃ©o tous les 15 Ã©pisodes
    #episode_trigger=lambda ep: ep == (N-1)  # N = nombre d'Ã©pisodes total Pour enregistrer que une video a la fin
)


# ğŸ§  Initialise le modÃ¨le PPO
model = PPO(
    policy="MlpPolicy",
    env=env,
    verbose=1,
    tensorboard_log="./tensorboard_logs"
)

# ğŸƒâ€â™‚ï¸ Lance lâ€™entraÃ®nement sur 50â€¯000 steps
model.learn(total_timesteps=5_500_000)

# ğŸ’¾ Sauvegarde le policy au format ONNX
onnx_path = os.path.join(OUTPUT_DIR, "policy.onnx")

#model.policy.export(onnx_path) #Need to change this. 
export_policy_to_onnx(model.policy, env, onnx_path)

print(f"âœ… ModÃ¨le exportÃ© : {onnx_path}")

env.close()
print(f"ğŸ¥ VidÃ©os sauvegardÃ©es dans {os.path.join(OUTPUT_DIR, 'videos')}")
